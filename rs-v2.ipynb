{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "import cv, os, glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Dataset\n",
    "First, the data is prepared. To this end, all the training/test/validation files are loaded into dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './ds/train/'\n",
    "test_dir = './ds/test/'\n",
    "\n",
    "classes = [os.path.basename(x[0]) for x in os.walk(\"./ds/train\") if x[0]][1:]\n",
    "num_classes = len(classes)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = []\n",
    "    for c, category in enumerate(classes):\n",
    "        images = [os.path.join(dp, f) for dp, dn, filenames in os.walk(path + category) for f in filenames]\n",
    "\n",
    "        for img_path in images:\n",
    "            # Note that we apply the same preprocessing and target images of size 224x224\n",
    "            # in order to match the setup of original VGG16 model\n",
    "            img = image.load_img(img_path, target_size=(224, 224))  \n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x) \n",
    "\n",
    "            data.append({'x' : np.array(x[0]), 'y' : c})\n",
    "            # data.append({'x' : np.array(img), 'y' : c})\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "data_train_val = load_data(train_dir)\n",
    "data_test = load_data(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up all arrays for train, test, validation\n",
    "X_train_val, y_train_val = np.array([t[\"x\"] for t in data_train_val]), [t[\"y\"] for t in data_train_val]\n",
    "X_test, y_test = np.array([t[\"x\"] for t in data_test]), [t[\"y\"] for t in data_test]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state=42, test_size=0.2)\n",
    "\n",
    "# Convert classes to one-hot vectors\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print('Train images:', len(y_train), y_train.shape)\n",
    "print('Test images:', len(y_test), y_test.shape)\n",
    "print('Val images:', len(y_val), y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Data analysis and initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train_val, return_counts=True)\n",
    "ticks = np.arange(len(counts))\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.grid(color='w', axis='y')\n",
    "plt.bar(ticks, counts)\n",
    "plt.xticks(ticks, classes, rotation=75)\n",
    "plt.title('Number of images per class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = keras.applications.VGG16(weights='imagenet', include_top=True)\n",
    "inp = vgg.input\n",
    "\n",
    "# make a new softmax layer with num_classes neurons\n",
    "new_classification_layer = Dense(num_classes, activation='softmax')\n",
    "\n",
    "# connect our new layer to the second to last layer in VGG, and make a reference to it\n",
    "out = new_classification_layer(vgg.layers[-2].output)\n",
    "\n",
    "# create a new network between inp and out\n",
    "model_new = keras.models.Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all layers untrainable by freezing weights (except for last layer)\n",
    "for l, layer in enumerate(model_new.layers[:-1]):\n",
    "    layer.trainable = False\n",
    "\n",
    "# ensure the last layer is trainable/not frozen\n",
    "for l, layer in enumerate(model_new.layers[-1:]):\n",
    "    layer.trainable = True\n",
    "\n",
    "model_new.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model_new.fit(X_train, y_train, \n",
    "                         batch_size=128,\n",
    "                         epochs=10,\n",
    "                         validation_data=(X_val, y_val),\n",
    "                         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model_new.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9975a71c6d7ff9b9547f9907661bca7a033cdc6e7c87f596a27a936a2886f07d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
