{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score, f1_score, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the test and training data into variables. Images are already processed here, i.e. correctly sized, converted to numpy arrays and preprocessed similir to EfficientNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './ds/train/'\n",
    "test_dir = './ds/test/'\n",
    "\n",
    "classes = [os.path.basename(x[0]) for x in os.walk(\"./ds/train\") if x[0]][1:]\n",
    "num_classes = len(classes)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = []\n",
    "    for c, category in enumerate(classes):\n",
    "        images = [os.path.join(dp, f) for dp, dn, filenames in os.walk(path + category) for f in filenames]\n",
    "\n",
    "        for img_path in images:\n",
    "            img = image.load_img(img_path, target_size=(224, 224))  \n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "\n",
    "            data.append({'x' : np.array(x[0]), 'y' : c})\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "data_train_val = load_data(train_dir)\n",
    "data_test = load_data(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, y_train_val = np.array([t[\"x\"] for t in data_train_val]), [t[\"y\"] for t in data_train_val]\n",
    "X_test, y_test = np.array([t[\"x\"] for t in data_test]), [t[\"y\"] for t in data_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the class distribution. It becomes visible that the dataset is imbalanced since some classes are twice as large as others. This will impact the model's performance as visible in the later evaluation but for the baseline_v1 model, we leave this unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train_val, return_counts=True)\n",
    "ticks = np.arange(len(counts))\n",
    "class_dist = sorted(zip(classes, counts), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.grid(color='w', axis='y')\n",
    "plt.bar(ticks, [c[1] for c in class_dist])\n",
    "plt.xticks(ticks, [c[0][:4] for c in class_dist], rotation=75)\n",
    "plt.title('Number of images per class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is split into train and validation. The latter is used during model fitting while the test data is solely used to evaluate the final performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state=42, test_size=0.2)\n",
    "\n",
    "# Convert classes to one-hot vectors\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print('Train images:', len(y_train), y_train.shape)\n",
    "print('Test images:', len(y_test), y_test.shape)\n",
    "print('Val images:', len(y_val), y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a CNN model with fairly standard architecture. Then, fit and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    print(\"Input dimensions:\", X_train.shape[1:])\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=X_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = get_model()\n",
    "\n",
    "baseline_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoints during training\n",
    "filepath = './models/baseline_v1/baseline_v1_{epoch:02d}_{val_accuracy:.2f}.hdf5'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Train the model\n",
    "history = baseline_model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=25,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=callbacks_list,\n",
    "                    workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize training progress along epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the (val_)accuracy and (val_)loss along epochs to identify over- and underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(history.history[\"val_loss\"], label='validation')\n",
    "ax.plot(history.history[\"loss\"], label='train')\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_title(\"Loss\")\n",
    "ax.set_xlabel(\"epochs\")\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(history.history[\"val_accuracy\"], label='validation')\n",
    "ax2.plot(history.history[\"accuracy\"], label='train')\n",
    "ax2.legend(loc=\"lower right\")\n",
    "ax2.set_title(\"Accuracy\")\n",
    "ax2.set_xlabel(\"epochs\")\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of model performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: By default, the finished model is loaded from the repository in order to evaluate\n",
    "# without compiling and fitting the model again. However, if you train again,\n",
    "# uncomment the following line and comment the load_model() call below\n",
    "\n",
    "# test_model = baseline_model\n",
    "test_model = keras.models.load_model('./models/baseline_v1/baseline_v1_epochs=17_acc=20.h5')\n",
    "\n",
    "y_pred = test_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis = 1)\n",
    "y_true = np.argmax(y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of predicted classes\n",
    "\n",
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "ticks = np.arange(len(counts))\n",
    "pred_dist = sorted(zip(classes, counts), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.grid(color='w', axis='y')\n",
    "plt.bar(ticks, [c[1] for c in pred_dist])\n",
    "plt.xticks(ticks, [c[0][:4] for c in pred_dist], rotation=75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix and evaluate acc, prec and f1\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=[c[:4] for c in classes])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cmd.plot(ax=ax, xticks_rotation='vertical')\n",
    "cmd.ax_.set_title(\"Confusion Matrix: baseline_v1_102_0.50.hdf5\")\n",
    "\n",
    "print('Acc: ', accuracy_score(y_true, y_pred))\n",
    "print('Prec: ', precision_score(y_true, y_pred, average='weighted'))\n",
    "print('F1: ', f1_score(y_true, y_pred, average='weighted'))\n",
    "# Acc:  0.20430107526881722\n",
    "# Prec:  0.2233363908095091\n",
    "# F1:  0.17318998111272751"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9975a71c6d7ff9b9547f9907661bca7a033cdc6e7c87f596a27a936a2886f07d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
